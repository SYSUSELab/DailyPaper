[
  {
    "id": "1908.09804",
    "title": "Neural Code Search Evaluation Dataset",
    "abstract": "There has been an increase of interest in code search using natural language. Assessing the performance of such code search models can be difficult without a readily available evaluation suite. In this paper, we present an evaluation dataset consisting of natural language query and code snippet pairs, with the hope that future work in this area can use this dataset as a common benchmark. We also provide the results of two code search models ([1] and [6]) from recent work.   The evaluation dataset is available at https://github.com/facebookresearch/Neural-Code-Search-Evaluation-Dataset",
    "arxiv_url": "https://arxiv.org/abs/1908.09804",
    "authors": [
      "Hongyu Li",
      "Seohyun Kim",
      "Satish Chandra"
    ],
    "first_author": "Hongyu Li",
    "category": [
      "Benchmark"
    ],
    "field": "Coding Assistant",
    "task": "Code Retrieval",
    "tags": [
      "Stack Overflow Q&A curation",
      "Method-level code extraction",
      "Android-focused search corpus",
      "GitHub commit-aware indexing",
      "Automatic code-to-code relevance labeling",
      "Evaluation metrics (MRR, Answered@k)"
    ],
    "summary": "该论文发布了一个面向自然语言到代码检索的评估数据集，包含约4.7M个方法级搜索语料、287个经人工筛选的Stack Overflow问答对以及用于自动判定相关性的相似度标注和基准模型评测结果。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/1908.09804v6",
    "published": "2019-08-26",
    "update_time": "2019-10-02",
    "download_time": "2025-12-11 17:45:08"
  }
]