[
  {
    "id": "2207.01780",
    "title": "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning",
    "abstract": "Program synthesis or code generation aims to generate a program that satisfies a problem specification. Recent approaches using large-scale pretrained language models (LMs) have shown promising results, yet they have some critical limitations. In particular, they often follow a standard supervised fine-tuning procedure to train a code generation model only from the pairs of natural-language problem descriptions and ground-truth programs. Such paradigm largely ignores some important but potentially useful signals in the problem specification such as unit tests, which thus often results in poor performance when solving complex unseen coding tasks. To address the limitations, we propose \"CodeRL\", a new framework for program synthesis tasks through pretrained LMs and deep reinforcement learning (RL). Specifically, during training, we treat the code-generating LM as an actor network, and introduce a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor. During inference, we introduce a new generation procedure with a critical sampling strategy that allows a model to automatically regenerate programs based on feedback from example unit tests and critic scores. For the model backbones, we extended the encoder-decoder architecture of CodeT5 with enhanced learning objectives, larger model sizes, and better pretraining data. Our method not only achieves new SOTA results on the challenging APPS benchmark, but also shows strong zero-shot transfer capability with new SOTA results on the simpler MBPP benchmark.",
    "arxiv_url": "https://arxiv.org/abs/2207.01780",
    "authors": [
      "Hung Le",
      "Yue Wang",
      "Akhilesh Deepak Gotmare",
      "Silvio Savarese",
      "Steven C. H. Hoi"
    ],
    "first_author": "Hung Le",
    "category": [
      "Technical / Method"
    ],
    "field": "Coding Assistant",
    "tag": "Code Reasoning",
    "summary": "本文提出CodeRL框架，将预训练代码语言模型作为actor并引入critic与基于单元测试的奖励和关键采样策略，通过深度强化学习优化代码生成与自动修复，在APPS和MBPP上取得新的SOTA表现。",
    "quality": "High",
    "conference": "NeurIPS 2022",
    "pdf_url": "https://arxiv.org/pdf/2207.01780v3",
    "published": "2022-07-05",
    "update_time": "2022-11-03",
    "download_time": "2025-12-04 23:19:47"
  },
  {
    "id": "2207.10397",
    "title": "CodeT: Code Generation with Generated Tests",
    "abstract": "The task of generating code solutions for a given programming problem can benefit from the use of pre-trained language models such as Codex, which can produce multiple diverse samples. However, a major challenge for this task is to select the most appropriate solution from the multiple samples generated by the pre-trained language models. A natural way to evaluate the quality and correctness of a code solution is to run it against a set of test cases, but the manual creation of such test cases is often costly and time-consuming. In this paper, we propose a novel method, CodeT, that leverages the same pre-trained language models to automatically generate test cases for the code samples, thus reducing the human effort and increasing the coverage of the test scenarios. CodeT then executes the code samples using the generated test cases, and performs a dual execution agreement, which considers both the consistency of the outputs against the generated test cases and the agreement of the outputs with other code samples. We conduct comprehensive experiments on four benchmarks, HumanEval, MBPP, APPS and CodeContests, using five different pre-trained language models with varying sizes and capabilities. Our results show that CodeT can significantly improve the performance of code solution selection over previous methods, achieving remarkable and consistent gains across different models and benchmarks. For instance, CodeT improves the pass@1 metric on HumanEval to 65.8%, which represents an absolute improvement of 18.8% over the code-davinci-002 model, and an absolute improvement of more than 20% over the previous state-of-the-art results.",
    "arxiv_url": "https://arxiv.org/abs/2207.10397",
    "authors": [
      "Bei Chen",
      "Fengji Zhang",
      "Anh Nguyen",
      "Daoguang Zan",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "first_author": "Bei Chen",
    "category": [
      "Technical"
    ],
    "field": "Coding Assistant",
    "tag": "Code Completion",
    "summary": "论文提出CODET方法，利用同一预训练模型自动生成测试用例并通过双重执行一致性（基于生成测试的输出匹配和候选程序间的一致性）从多个候选解中选出最佳代码，从而在HumanEval、MBPP、APPS等基准上显著提升了pass@1性能。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/2207.10397v2",
    "published": "2022-07-21",
    "update_time": "2022-11-23",
    "download_time": "2025-12-04 23:24:02"
  }
]