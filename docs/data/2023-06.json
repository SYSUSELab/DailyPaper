[
  {
    "id": "2306.10763",
    "title": "Guiding Language Models of Code with Global Context using Monitors",
    "abstract": "Language models of code (LMs) work well when the surrounding code provides sufficient context. This is not true when it becomes necessary to use types, functionality or APIs defined elsewhere in the repository or a linked library, especially those not seen during training. LMs suffer from limited awareness of such global context and end up hallucinating.   Integrated development environments (IDEs) assist developers in understanding repository context using static analysis. We extend this assistance, enjoyed by developers, to LMs. We propose monitor-guided decoding (MGD) where a monitor uses static analysis to guide the decoding. We construct a repository-level dataset PragmaticCode for method-completion in Java and evaluate MGD on it. On models of varying parameter scale, by monitoring for type-consistent object dereferences, MGD consistently improves compilation rates and agreement with ground truth. Further, LMs with fewer parameters, when augmented with MGD, can outperform larger LMs. With MGD, SantaCoder-1.1B achieves better compilation rate and next-identifier match than the much larger text-davinci-003 model.   We also conduct a generalizability study to evaluate the ability of MGD to generalize to multiple programming languages (Java, C# and Rust), coding scenarios (e.g., correct number of arguments to method calls), and to enforce richer semantic constraints (e.g., stateful API protocols). Our data and implementation are available at https://github.com/microsoft/monitors4codegen .",
    "arxiv_url": "https://arxiv.org/abs/2306.10763",
    "authors": [
      "Lakshya A Agrawal",
      "Aditya Kanade",
      "Navin Goyal",
      "Shuvendu K. Lahiri",
      "Sriram K. Rajamani"
    ],
    "first_author": "Lakshya A Agrawal",
    "category": [
      "Technical",
      "Benchmark"
    ],
    "field": "Coding Assistant",
    "task": "Code Completion",
    "tags": [
      "Monitor-guided decoding",
      "Static-analysis-driven token masking",
      "Language Server Protocol integration",
      "Type-aware identifier resolution",
      "Decoding-time semantic constraints",
      "Repository-level context",
      "Stateful API protocol enforcement",
      "Compilation-focused evaluation"
    ],
    "summary": "本文提出监视器引导解码（MGD），在解码阶段调用静态分析（基于LSP）对模型生成的令牌进行约束，从而利用仓库级全局上下文提升类型一致性、编译率和与真实代码的匹配，并公开了相应的仓库级数据集与工具实现。",
    "quality": "High",
    "conference": "NeurIPS 2023",
    "pdf_url": "https://arxiv.org/pdf/2306.10763v2",
    "published": "2023-06-19",
    "update_time": "2023-11-03",
    "download_time": "2025-12-11 16:30:53"
  },
  {
    "id": "2306.10998",
    "title": "RepoFusion: Training Code Models to Understand Your Repository",
    "abstract": "Despite the huge success of Large Language Models (LLMs) in coding assistants like GitHub Copilot, these models struggle to understand the context present in the repository (e.g., imports, parent classes, files with similar names, etc.), thereby producing inaccurate code completions. This effect is more pronounced when using these assistants for repositories that the model has not seen during training, such as proprietary software or work-in-progress code projects. Recent work has shown the promise of using context from the repository during inference. In this work, we extend this idea and propose RepoFusion, a framework to train models to incorporate relevant repository context. Experiments on single-line code completion show that our models trained with repository context significantly outperform much larger code models as CodeGen-16B-multi ($\\sim73\\times$ larger) and closely match the performance of the $\\sim 70\\times$ larger StarCoderBase model that was trained with the Fill-in-the-Middle objective. We find these results to be a novel and compelling demonstration of the gains that training with repository context can bring. We carry out extensive ablation studies to investigate the impact of design choices such as context type, number of contexts, context length, and initialization within our framework. Lastly, we release Stack-Repo, a dataset of 200 Java repositories with permissive licenses and near-deduplicated files that are augmented with three types of repository contexts. Additionally, we are making available the code and trained checkpoints for our work. Our released resources can be found at \\url{https://huggingface.co/RepoFusion}.",
    "arxiv_url": "https://arxiv.org/abs/2306.10998",
    "authors": [
      "Disha Shrivastava",
      "Denis Kocetkov",
      "Harm de Vries",
      "Dzmitry Bahdanau",
      "Torsten Scholak"
    ],
    "first_author": "Disha Shrivastava",
    "category": [
      "Technical",
      "Benchmark"
    ],
    "field": "Coding Assistant",
    "task": "Code Completion",
    "tags": [
      "Repository-level context integration",
      "Fusion-in-Decoder adaptation",
      "Repo-level prompt proposals",
      "Context retrieval (BM25 and embedding-based)",
      "Surrounding-context augmentation",
      "Single-line code completion",
      "Ablation studies on context design",
      "Java repository corpus release"
    ],
    "summary": "本文提出RepoFusion，通过将多个仓库级上下文用Fusion-in-Decoder训练融入代码模型以提升单行代码补全性能，并发布了带上下文增强的Java仓库语料与训练检查点，且小模型在多项评测中显著优于更大的基线模型。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/2306.10998v1",
    "published": "2023-06-19",
    "update_time": "2023-06-19",
    "download_time": "2025-12-11 16:31:32"
  },
  {
    "id": "2306.17193",
    "title": "Uncovering the Limits of Machine Learning for Automatic Vulnerability Detection",
    "abstract": "Recent results of machine learning for automatic vulnerability detection (ML4VD) have been very promising. Given only the source code of a function $f$, ML4VD techniques can decide if $f$ contains a security flaw with up to 70% accuracy. However, as evident in our own experiments, the same top-performing models are unable to distinguish between functions that contain a vulnerability and functions where the vulnerability is patched. So, how can we explain this contradiction and how can we improve the way we evaluate ML4VD techniques to get a better picture of their actual capabilities?   In this paper, we identify overfitting to unrelated features and out-of-distribution generalization as two problems, which are not captured by the traditional approach of evaluating ML4VD techniques. As a remedy, we propose a novel benchmarking methodology to help researchers better evaluate the true capabilities and limits of ML4VD techniques. Specifically, we propose (i) to augment the training and validation dataset according to our cross-validation algorithm, where a semantic preserving transformation is applied during the augmentation of either the training set or the testing set, and (ii) to augment the testing set with code snippets where the vulnerabilities are patched.   Using six ML4VD techniques and two datasets, we find (a) that state-of-the-art models severely overfit to unrelated features for predicting the vulnerabilities in the testing data, (b) that the performance gained by data augmentation does not generalize beyond the specific augmentations applied during training, and (c) that state-of-the-art ML4VD techniques are unable to distinguish vulnerable functions from their patches.",
    "arxiv_url": "https://arxiv.org/abs/2306.17193",
    "authors": [
      "Niklas Risse",
      "Marcel Böhme"
    ],
    "first_author": "Niklas Risse",
    "category": [
      "Empirical",
      "Benchmark",
      "Technical"
    ],
    "field": "Quality Management",
    "task": "Vulnerability Detection",
    "tags": [
      "Semantic-preserving code transformations",
      "Overfitting to superficial features",
      "Cross-transformation generalization",
      "Patch-pair evaluation",
      "Data augmentation robustness",
      "Vuln–patch paired dataset",
      "Evaluation algorithms for ML4VD",
      "Out-of-distribution generalization"
    ],
    "summary": "本文提出两种用于评估自动化漏洞检测（ML4VD）的算法并发布包含漏洞与对应补丁对的新数据集，实验证明现有基于令牌的模型严重依赖与漏洞无关的特征且无法区分漏洞与其补丁。",
    "quality": "High",
    "conference": "Proceedings of the 33rd USENIX Security Symposium (USENIX Security 2024) 2024",
    "pdf_url": "https://arxiv.org/pdf/2306.17193v2",
    "published": "2023-06-28",
    "update_time": "2024-06-06",
    "download_time": "2025-12-11 17:14:01"
  }
]