[
  {
    "id": "2301.03988",
    "title": "SantaCoder: don't reach for the stars!",
    "abstract": "The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.",
    "arxiv_url": "https://arxiv.org/abs/2301.03988",
    "authors": [
      "Loubna Ben Allal",
      "Raymond Li",
      "Denis Kocetkov",
      "Chenghao Mou",
      "Christopher Akiki",
      "Carlos Munoz Ferrandis",
      "Niklas Muennighoff",
      "Mayank Mishra",
      "Alex Gu",
      "Manan Dey",
      "Logesh Kumar Umapathi",
      "Carolyn Jane Anderson",
      "Yangtian Zi",
      "Joel Lamy Poirier",
      "Hailey Schoelkopf",
      "Sergey Troshin",
      "Dmitry Abulkhanov",
      "Manuel Romero",
      "Michael Lappert",
      "Francesco De Toni",
      "Bernardo García del Río",
      "Qian Liu",
      "Shamik Bose",
      "Urvashi Bhattacharyya",
      "Terry Yue Zhuo",
      "Ian Yu",
      "Paulo Villegas",
      "Marco Zocca",
      "Sourab Mangrulkar",
      "David Lansky",
      "Huu Nguyen",
      "Danish Contractor",
      "Luis Villa",
      "Jia Li",
      "Dzmitry Bahdanau",
      "Yacine Jernite",
      "Sean Hughes",
      "Daniel Fried",
      "Arjun Guha",
      "Harm de Vries",
      "Leandro von Werra"
    ],
    "first_author": "Loubna Ben Allal",
    "category": [
      "Technical / Method",
      "Benchmark / Dataset",
      "Experience / Empirical"
    ],
    "field": "Coding Assistant",
    "tag": "Code Pre-Training",
    "summary": "该技术报告介绍了BigCode社区训练的1.1B参数代码模型SantaCoder，包含PII删减管道、架构（MQA、FIM）与数据预处理的消融实验，并在MultiPL-E上优于之前开源多语言模型。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/2301.03988v2",
    "published": "2023-01-09",
    "update_time": "2023-02-24",
    "download_time": "2025-12-04 23:15:33"
  },
  {
    "id": "2301.13816",
    "title": "Execution-based Code Generation using Deep Reinforcement Learning",
    "abstract": "The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important to note that PPOCoder is a task-agnostic and model-agnostic framework that can be used across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, achieving significant improvements in compilation success rates and functional correctness across different PLs.",
    "arxiv_url": "https://arxiv.org/abs/2301.13816",
    "authors": [
      "Parshin Shojaee",
      "Aneesh Jain",
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "first_author": "Parshin Shojaee",
    "category": [
      "Technical / Method"
    ],
    "field": "Coding Assistant",
    "tag": "Code Completion",
    "summary": "该论文提出PPOCoder——一种将预训练代码模型与PPO强化学习结合、利用编译器执行和代码结构对齐作为不可微奖励来优化代码生成以提高可编译性和功能正确性的通用框架，并在多种编程语言与任务上显著优于现有方法。",
    "quality": "High",
    "conference": "TMLR 2023",
    "pdf_url": "https://arxiv.org/pdf/2301.13816v4",
    "published": "2023-01-31",
    "update_time": "2023-07-19",
    "download_time": "2025-12-04 23:19:17"
  }
]