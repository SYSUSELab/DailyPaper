[
  {
    "id": "2301.03988",
    "title": "SantaCoder: don't reach for the stars!",
    "abstract": "The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.",
    "arxiv_url": "https://arxiv.org/abs/2301.03988",
    "authors": [
      "Loubna Ben Allal",
      "Raymond Li",
      "Denis Kocetkov",
      "Chenghao Mou",
      "Christopher Akiki",
      "Carlos Munoz Ferrandis",
      "Niklas Muennighoff",
      "Mayank Mishra",
      "Alex Gu",
      "Manan Dey",
      "Logesh Kumar Umapathi",
      "Carolyn Jane Anderson",
      "Yangtian Zi",
      "Joel Lamy Poirier",
      "Hailey Schoelkopf",
      "Sergey Troshin",
      "Dmitry Abulkhanov",
      "Manuel Romero",
      "Michael Lappert",
      "Francesco De Toni",
      "Bernardo García del Río",
      "Qian Liu",
      "Shamik Bose",
      "Urvashi Bhattacharyya",
      "Terry Yue Zhuo",
      "Ian Yu",
      "Paulo Villegas",
      "Marco Zocca",
      "Sourab Mangrulkar",
      "David Lansky",
      "Huu Nguyen",
      "Danish Contractor",
      "Luis Villa",
      "Jia Li",
      "Dzmitry Bahdanau",
      "Yacine Jernite",
      "Sean Hughes",
      "Daniel Fried",
      "Arjun Guha",
      "Harm de Vries",
      "Leandro von Werra"
    ],
    "first_author": "Loubna Ben Allal",
    "category": [
      "Technical",
      "Benchmark",
      "Empirical"
    ],
    "field": "Coding Assistant",
    "task": "Code Pre-Training",
    "summary": "该技术报告介绍了BigCode社区训练的1.1B参数代码模型SantaCoder，包含PII删减管道、架构（MQA、FIM）与数据预处理的消融实验，并在MultiPL-E上优于之前开源多语言模型。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/2301.03988v2",
    "published": "2023-01-09",
    "update_time": "2023-02-24",
    "download_time": "2025-12-04 23:15:33"
  },
  {
    "id": "2301.13816",
    "title": "Execution-based Code Generation using Deep Reinforcement Learning",
    "abstract": "The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important to note that PPOCoder is a task-agnostic and model-agnostic framework that can be used across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, achieving significant improvements in compilation success rates and functional correctness across different PLs.",
    "arxiv_url": "https://arxiv.org/abs/2301.13816",
    "authors": [
      "Parshin Shojaee",
      "Aneesh Jain",
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "first_author": "Parshin Shojaee",
    "category": [
      "Technical"
    ],
    "field": "Coding Assistant",
    "task": "Code Completion",
    "summary": "该论文提出PPOCoder——一种将预训练代码模型与PPO强化学习结合、利用编译器执行和代码结构对齐作为不可微奖励来优化代码生成以提高可编译性和功能正确性的通用框架，并在多种编程语言与任务上显著优于现有方法。",
    "quality": "High",
    "conference": "TMLR 2023",
    "pdf_url": "https://arxiv.org/pdf/2301.13816v4",
    "published": "2023-01-31",
    "update_time": "2023-07-19",
    "download_time": "2025-12-04 23:19:17"
  },
  {
    "id": "2301.03270",
    "title": "A Survey of Learning-based Automated Program Repair",
    "abstract": "Automated program repair (APR) aims to fix software bugs automatically and plays a crucial role in software development and maintenance. With the recent advances in deep learning (DL), an increasing number of APR techniques have been proposed to leverage neural networks to learn bug-fixing patterns from massive open-source code repositories. Such learning-based techniques usually treat APR as a neural machine translation (NMT) task, where buggy code snippets (i.e., source language) are translated into fixed code snippets (i.e., target language) automatically. Benefiting from the powerful capability of DL to learn hidden relationships from previous bug-fixing datasets, learning-based APR techniques have achieved remarkable performance. In this paper, we provide a systematic survey to summarize the current state-of-the-art research in the learning-based APR community. We illustrate the general workflow of learning-based APR techniques and detail the crucial components, including fault localization, patch generation, patch ranking, patch validation, and patch correctness phases. We then discuss the widely-adopted datasets and evaluation metrics and outline existing empirical studies. We discuss several critical aspects of learning-based APR techniques, such as repair domains, industrial deployment, and the open science issue. We highlight several practical guidelines on applying DL techniques for future APR studies, such as exploring explainable patch generation and utilizing code features. Overall, our paper can help researchers gain a comprehensive understanding about the achievements of the existing learning-based APR techniques and promote the practical application of these techniques. Our artifacts are publicly available at \\url{https://github.com/QuanjunZhang/AwesomeLearningAPR}.",
    "arxiv_url": "https://arxiv.org/abs/2301.03270",
    "authors": [
      "Quanjun Zhang",
      "Chunrong Fang",
      "Yuxiang Ma",
      "Weisong Sun",
      "Zhenyu Chen"
    ],
    "first_author": "Quanjun Zhang",
    "category": [
      "Survey"
    ],
    "field": "Quality Management",
    "task": "Bug Repair",
    "tags": [
      "Neural Machine Translation formulation",
      "Fault Localization",
      "Patch Generation",
      "Patch Ranking & Validation",
      "Code Representation: Sequence/Tree/Graph",
      "Pre-trained Models for APR",
      "Evaluation: Plausible vs Correct Patches",
      "Multilingual and Multi-hunk Repair",
      "Explainable Patch Generation",
      "Open Science and Reproducibility"
    ],
    "summary": "本文系统综述了基于深度学习的自动程序修复（APR）研究，梳理了常见工作流程与关键组件、数据集与评测指标、实证研究、挑战与未来方向。",
    "quality": "High",
    "conference": "ACM Transactions on Software Engineering and Methodology (TOSEM) 2023",
    "pdf_url": "https://arxiv.org/pdf/2301.03270v3",
    "published": "2023-01-09",
    "update_time": "2023-11-01",
    "download_time": "2025-12-11 16:56:32"
  }
]