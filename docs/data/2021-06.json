[
  {
    "id": "2106.01065",
    "title": "Towards Robustness of Text-to-SQL Models against Synonym Substitution",
    "abstract": "Recently, there has been significant progress in studying neural networks to translate text descriptions into SQL queries. Despite achieving good performance on some public benchmarks, existing text-to-SQL models typically rely on the lexical matching between words in natural language (NL) questions and tokens in table schemas, which may render the models vulnerable to attacks that break the schema linking mechanism. In this work, we investigate the robustness of text-to-SQL models to synonym substitution. In particular, we introduce Spider-Syn, a human-curated dataset based on the Spider benchmark for text-to-SQL translation. NL questions in Spider-Syn are modified from Spider, by replacing their schema-related words with manually selected synonyms that reflect real-world question paraphrases. We observe that the accuracy dramatically drops by eliminating such explicit correspondence between NL questions and table schemas, even if the synonyms are not adversarially selected to conduct worst-case adversarial attacks. Finally, we present two categories of approaches to improve the model robustness. The first category of approaches utilizes additional synonym annotations for table schemas by modifying the model input, while the second category is based on adversarial training. We demonstrate that both categories of approaches significantly outperform their counterparts without the defense, and the first category of approaches are more effective.",
    "arxiv_url": "https://arxiv.org/abs/2106.01065",
    "authors": [
      "Yujian Gan",
      "Xinyun Chen",
      "Qiuping Huang",
      "Matthew Purver",
      "John R. Woodward",
      "Jinxia Xie",
      "Pengsheng Huang"
    ],
    "first_author": "Yujian Gan",
    "category": [
      "Benchmark",
      "Technical",
      "Empirical"
    ],
    "field": "Coding Assistant",
    "task": "Code Translation",
    "tags": [
      "Synonym substitution robustness",
      "Schema linking vulnerability",
      "Human-curated paraphrase benchmark",
      "Schema annotation augmentation",
      "Adversarial training for robustness",
      "Cell-value paraphrasing",
      "Cross-domain text-to-SQL evaluation",
      "Input-level defense (multiple schema annotations)"
    ],
    "summary": "本文构建了一个人工整理的同义替换问句基准以评估并改进 text-to-SQL 模型对模式词同义替换的鲁棒性，提出通过多重模式注释的输入修改和对抗训练两类防御方法并验证其有效性，且输入修改方法在资源消耗更低的情况下表现更好。",
    "quality": "High",
    "conference": "ACL 2021",
    "pdf_url": "https://arxiv.org/pdf/2106.01065v2",
    "published": "2021-06-02",
    "update_time": "2021-06-19",
    "download_time": "2025-12-12 21:52:49"
  },
  {
    "id": "2106.05006",
    "title": "Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data",
    "abstract": "Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of natural language understanding systems. As a result, they do not contain any of the richness and variety of natural-occurring utterances, where humans ask about data they need or are curious about. In this work, we release SEDE, a dataset with 12,023 pairs of utterances and SQL queries collected from real usage on the Stack Exchange website. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.",
    "arxiv_url": "https://arxiv.org/abs/2106.05006",
    "authors": [
      "Moshe Hazoom",
      "Vibhor Malik",
      "Ben Bogin"
    ],
    "first_author": "Moshe Hazoom",
    "category": [
      "Benchmark",
      "Empirical"
    ],
    "field": "Coding Assistant",
    "task": "Code Translation",
    "tags": [
      "naturally-occurring SQL queries",
      "web-forum query logs",
      "under-specified questions",
      "parameterized queries",
      "nested subqueries",
      "high template diversity",
      "data cleaning & validation",
      "partial-clause evaluation (PCM-F1)",
      "query canonization & anonymization"
    ],
    "summary": "本文发布了SEDE，一个由Stack Exchange Data Explorer真实用户生成的12,023条自然语言与对应SQL对的数据集，分析了其中的真实世界挑战（如欠定问题与参数化查询）、提出了基于部分子句匹配的评估指标PCM-F1，并展示了在该数据集上现有模型性能明显下降。",
    "quality": "High",
    "conference": null,
    "pdf_url": "https://arxiv.org/pdf/2106.05006v1",
    "published": "2021-06-09",
    "update_time": "2021-06-09",
    "download_time": "2025-12-12 21:53:32"
  }
]