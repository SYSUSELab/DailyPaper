source_paper,benchmark_name,benchmark_name_quote,is_original_proposal,is_original_proposal_quote,dataset_url,dataset_url_quote,task_description,task_description_quote,dimension,dimension_quote,evaluation_method,evaluation_method_quote,context_dependency,context_dependency_quote,problem_domain,problem_domain_quote,problem_difficulty,problem_difficulty_quote,language,language_quote,data_size,data_size_quote,source_type,source_type_quote,last_updated,last_updated_quote,build_type,build_type_quote,contamination_status,contamination_status_quote,dataset_license,dataset_license_quote,task_granularity,task_granularity_quote,evaluation_metrics,evaluation_metrics_quote,input_modality,input_modality_quote,output_modality,output_modality_quote,task_io_type,task_io_type_quote,execution_environment,execution_environment_quote,unique_features,unique_features_quote
2511.20403_output/content.md,CLASSES2TEST,"We introduce the CLASSES2TEST dataset, which maps Java classes under test to their corresponding test classes",Yes，本文是该数据集的原始发布论文,"We introduce the CLASSES2TEST dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics",https://anonymous.4open.science/r/classes2test,1https://anonymous.4open.science/r/classes2test,用于评估大型语言模型生成的Java单元测试的质量，支持研究人员和开发者比较不同LLM和提示策略,"AGONETEST does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions.",单元测试质量评估，包括编译成功率、代码覆盖率、缺陷检测能力、测试异味等,"a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment",集成高级评估指标，如变异分数和测试异味，进行综合评估,"a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment",类级别测试，涵盖方法交互和共享状态,"Our approach focuses on class-level test code evaluation, which is closer to real-world practices as it covers method interactions and shared state",软件测试，Java单元测试生成,"Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly.",现实世界软件项目级别，比单方法测试更复杂,This extended dataset makes it possible to assess the test performance of an LLM on a more complex scope (the entire class) than the single method.,Java,An annotated open source Java project dataset extending METHODS2TEST [9],"基于9,410个GitHub仓库的数据集","AGONETEST offers far broader applicability by using a dataset of 9,410 GitHub repositories",扩展自METHODS2TEST数据集的Java开源项目,An annotated open source Java project dataset extending METHODS2TEST [9],2025,arXiv:2511.20403v1  [cs.SE]  25 Nov 2025,官方自建，基于现有数据集扩展,"Leveraging the METHODS2TEST dataset [9], we developed a new dataset specifically aimed at comparing human-written tests with those produced by LLMs.",,,,,类级别单元测试生成,"Our approach focuses on class-level test code evaluation, which is closer to real-world practices as it covers method interactions and shared state",变异分数、测试异味、代码覆盖率,"a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment",Java类代码,which maps classes under test to their related test classes,单元测试代码,"for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection",代码到代码,which maps Java classes under test to their corresponding test classes,支持所有Java LTS版本的项目环境,AGONETEST overcomes this barrier by supporting all Java LTS versions.,专注于类级别测试评估，支持多种LLM和提示策略的比较，提供端到端的自动化评估流水线,"AGONETEST shifts the focus to the generation of class-level tests. Our approach makes it possible to use up-to-date LLMs and not constrain prompt design (our prompts can be customized), thereby handling more complex, real-world scenarios."
2511.21380_output/content.md,"ROCODE, LogHub2.0","Two projects (i.e., ROCODE [15] and LogHub2.0 [16]) are selected for the following experiments.","No, 本文是使用该数据集进行评测","We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0.",,,数据集适应任务 - 将软件工程研究工具自动适配到新的数据集，构建可运行的实验并获取执行结果,"Our objective is to automatically modify 𝑅𝐷or 𝑅𝑇, construct a runnable experiment, and obtain its execution results.",多智能体系统在数据集适应任务中的能力评估,This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks.,五阶段评估流程：文件理解、代码编辑、命令生成、验证和最终执行，测量成功率并分析失败模式,"Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance.",多文件项目环境，需要理解整个代码仓库的架构,"Before modifying code or generating commands for a repository, a multi-agent system must browse the essential files in a repository to understand its architecture.",软件工程研究，包括代码生成、bug修复、性能分析和安全等领域,"In areas ranging from code generation and bug fixing to performance analysis and security, researchers are constantly proposing new techniques",复杂软件工程任务，需要多步骤协调和迭代修复,"Most of the evaluated multi-agent systems failed to complete the assigned tasks. Under such circumstances, nearly all results would be classified as failures",Python,"To ensure a consistent and manageable experimental environment, we retained only artifacts implemented in Python.","从顶级软件工程会议（FSE, ICSE, ASE, ISSTA）2024-2025年接受的论文中筛选的可重用研究构件","We began by collecting all papers accepted by the top four SE (FSE, ICSE, ASE and ISSTA) in 2024-2025 that were either (i) awarded a Reusable Artifact badge or (ii) explicitly identified by the authors as providing reusable artifacts.",学术研究构件，来自顶级软件工程会议的可重用研究项目,"To construct a representative set of high-quality SE research artifacts, we followed a systematic multi-stage selection process",2025,arXiv:2511.21380v1  [cs.SE]  26 Nov 2025,官方自建的研究构件集合,"We began by collecting all papers accepted by the top four SE (FSE, ICSE, ASE and ISSTA) in 2024-2025",,,,,代码编辑、文件创建、命令生成、验证修复,Edit and create necessary files... Generate and execute the commands... Validating and repairing,成功率、结构相似度（从7.25%到67.14%）、完成状态记录,Results show that... substantially improve structural similarity to ground truth (from 7.25% to 67.14%),代码仓库、自然语言提示,Each multi-agent system is provided with a processed repository... along with a simple prompt that specifies the adaptation task,修改后的代码、生成的脚本命令、执行结果,"the code adaptations performed to ensure compatibility, the executable scripts or commands derived for running the experiment, and the results produced by executing those scripts or commands",代码到代码的适应任务,"automatically modify 𝑅𝐷or 𝑅𝑇, construct a runnable experiment, and obtain its execution results",Python环境，需要可靠的部署环境,This choice allows for reliable environment deployment and isolates our investigation from environment setup challenges,专注于多智能体系统在数据集适应任务中的表现评估，采用五阶段评估流程，研究提示级干预对性能的影响,"This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. Through a five-stage evaluation pipeline... we measure success rates, analyze failure patterns, and assess prompt-based interventions"
2511.21022_output/content.md,EDAPIBench,"We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances.",Yes，本文是该数据集的原始发布论文,"We introduce EDAPIBench, a dedicated benchmark... We construct EDAPIBench—the first dedicated benchmark for evaluating deprecated API knowledge editing in LLMs",,,评估大语言模型中废弃API知识编辑的性能，专门用于测试模型编辑技术能否有效更新废弃API知识并生成最新的API,"a dedicated benchmark for evaluating deprecated API knowledge editing in LLMs... whether existing model editing methods can effectively update deprecated API knowledge within LLMs, and enable the edited models to correctly replace deprecated APIs with up-to-date ones",有效性、泛化性、可移植性、特异性,"comprehensively assess model editing performance across four key dimensions: Effectiveness, Generalization, Portability, Specificity",基于四个维度的评估：有效性（编辑后模型是否生成最新API）、泛化性（语义等价但语法变化的输入）、可移植性（不同输入但涉及相同废弃API）、特异性（保持与编辑任务无关输入的行为一致性）,Effectiveness: Measuring whether the edited model generates the up-to-date API for the original inputs; Generalization: Measuring whether it generates the up-to-date API on semantically equivalent but syntactically varied inputs; Portability: Measuring whether it generates the up-to-date API across different inputs... Specificity: Measuring whether it preserves consistent pre-editing behavior on inputs unrelated to the editing task,单函数级别的代码补全上下文,Our study frames the model editing scenario as a code completion task... we extract lines preceding the API invocation as candidate editing inputs (to prompt LLM API completion) and the invocation line as the target API (ground truth),软件工程、API维护、第三方库更新,deprecated APIs from 8 popular Python libraries... covering eight popular Python libraries such as PyTorch and TensorFlow,实际工程级难度，涉及真实世界废弃API的识别和更新,"Using these mappings, we extract 65,596 real-world functions from GitHub that call the up-to-date APIs",Python,deprecated APIs from 8 popular Python libraries... covering eight popular Python libraries such as PyTorch and TensorFlow,"包含70多个废弃API，超过3000个编辑实例，从GitHub提取了65,596个真实世界函数","featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances... we extract 65,596 real-world functions from GitHub",从GitHub真实项目代码中提取，基于已验证的API映射关系,"We begin with 145 verified API mappings (deprecated →up-to-date) from Wang et al. [49]... Using these mappings, we extract 65,596 real-world functions from GitHub that call the up-to-date APIs",2025-2026,Publication date: November 2026. arXiv:2511.21022v1 [cs.SE] 26 Nov 2025,官方自建，全自动构建,which can be fully automatically constructed... with fully automated construction,,,,,API级别的代码补全,"code completion tasks... during code completion, LLMs frequently suggest deprecated API invocations",基于四个维度的定性评估：有效性、泛化性、可移植性、特异性,"Effectiveness, Generalization, Portability, Specificity",代码片段,the editing input (a code snippet to be completed),API调用代码,"the specific correct, up-to-date API that should replace the deprecated one",代码到代码,code completion task... generating code,,,首个专门针对废弃API知识编辑的基准测试，支持全自动构建，包含四个维度的综合评估,"the first dedicated benchmark for evaluating deprecated API knowledge editing in LLMs, with fully automated construction, serving as a standardized, rigorous platform"
2511.19875_output/content.md,CodeFuse-CommitEval,"We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models.",Yes，本文是该数据集的原始发布论文,"We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models.",https://figshare.com/s/21fe4ec9cb960b52bffe,The dataset is publicly available at https://figshare.com/s/21fe4ec9cb960b52bffe.,"检测提交信息与代码变更之间的不一致性（Message-Code Inconsistency, MCI）",A Message-Code Inconsistency (MCI) occurs when the natural language description in a commit message does not accurately reflect the actual modifications in the associated code diff.,提交信息与代码变更的一致性检测能力,evaluate models for MCI detection,使用Recall、Precision、Specificity等指标评估模型检测结果,"Results show models detect inconsistent commits more reliably than consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%)",提交信息与对应的代码差异（diff）,"Each item of the verified dataset contains a commit message, the corresponding code diff, and the ground truth label",软件工程、版本控制、代码审查,Version control relies on commit messages to convey the rationale for code changes,需要语义理解和上下文推理的复杂任务,purpose inconsistencies require deeper semantic understanding and contextual reasoning,多种编程语言（基于ApacheCM数据集的多样性）,because of its diversity in programming languages and the high-quality commits,包含正负样本的平衡数据集,we generate a balanced dataset with both positive and negative samples,基于ApacheCM数据集，通过规则引导的突变生成不一致提交信息,"Built on the ApacheCM dataset for diversity and quality, we generate seven types of inconsistent messages through rule-guided mutations of originally consistent commits",2025,arXiv:2511.19875v1 [cs.SE] 25 Nov 2025,官方自建，结合LLM数据合成能力与现有提交语料库,We present a comprehensive pipeline for constructing MCI datasets. By combining the data synthesis capabilities of LLMs with existing commit corpora,通过双重验证确保数据质量,apply two-fold validation to verify both positive and negative samples,,,一致性检测,detecting inconsistencies between commit messages and code,"Recall, Precision, Specificity","average Recall 85.95%, Precision 80.28%, Specificity 63.8%",自然语言（提交信息）与代码差异,"Each item of the verified dataset contains a commit message, the corresponding code diff",二元分类（一致或不一致）,allowing the models to detect whether the commit is consistent or not,文本与代码到分类,detect whether the commit is consistent or not,,,首个专门用于MCI检测的基准，包含七种不一致类型，支持多种增强策略评估,CODEFUSE-COMMITEVAL is the first benchmarking work tailored for comprehensively evaluating LLM's MCI detection ability. We define seven mutation rules to guide powerful LLMs in generating various types of inconsistent commit messages
2511.20709_output/content.md,DUALGAUGE-BENCH,"we further curated DUALGAUGE-BENCH, a comprehensive benchmark suite of 154 programming tasks",Yes，本文是该数据集的原始发布论文,"We present DUALGAUGE, the first fully automated benchmarking framework... we also present DUALGAUGE-BENCH, a curated benchmark suite",https://anonymous.4open.science/r/DualBench-6D1D,"Our system source code, benchmark, and evaluation/study data can all be found at https://anonymous.4open.science/r/DualBench-6D1D",联合评估代码生成的安全性和功能性，确保生成的代码既满足功能规范又不会引入安全漏洞,rigorously evaluate the security and correctness of LLM-generated code in unison... ensuring that generated programs fulfill their specifications without introducing vulnerabilities,代码生成的安全性和功能性联合评估,designed to rigorously evaluate the security and correctness of LLM-generated code in unison,在沙盒环境中执行程序，针对功能和安全性测试套件运行，基于执行结果评估测试通过率和联合正确性-安全性指标,"executes it in a sandboxed environment against functional and security test suites, and evaluates the execution results against both test suites to report test pass rates and joint correctness-security metrics",单任务代码生成，基于自然语言提示生成完整程序,Given an pure-natural-language prompt as functional specification... generates the model's code output for the prompt,跨领域编程任务，涵盖多样化功能领域,spanning diverse functionality domains,,,语言无关，支持多种编程语言,This dataset design and curation process allow it to be agnostic to programming languages,包含154个编程任务，每个任务都配有功能和安全性测试套件,a comprehensive benchmark suite of 154 programming tasks... Each task/prompt is paired with both a functional test suite... and a security test suite,人工与LLM协同创建，通过多评分者的人类专业知识进行精炼和修正,"constructed these test suites through a human-and-LLM co-creation process—leveraging multiple LLMs to generate candidate tests, then refining and amending these with human expertise of multiple raters",2025,arXiv:2511.20709v1 [cs.SE] 24 Nov 2025,官方自建，基于规范测试范式,following a specification-based testing paradigm,,,,,代码生成,code generation... translating natural language prompts—typically serving as functional specifications—into programs,测试通过率、联合正确性-安全性指标,report test pass rates and joint correctness-security metrics,自然语言,Given an pure-natural-language prompt as functional specification,代码,generates the model's code output for the prompt,文本到代码,translating natural language prompts... into programs,沙盒隔离容器环境，支持依赖解析和环境配置,executes it in a sandboxed environment... The execution engine compiles and runs the model-generated code within isolated containers,首个支持安全性和功能性联合评估的基准套件，每个任务都配有覆盖驱动的功能和安全性测试套件，采用人工与LLM协同创建过程,"the first benchmark suite that pairs each code-generation prompt with dual (functional and security), coverage-enforced test suites... constructed through a human-and-LLM co-creation process"
